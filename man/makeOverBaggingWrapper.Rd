% Generated by roxygen2 (4.0.1): do not edit by hand
\name{makeOverBaggingWrapper}
\alias{makeOverBaggingWrapper}
\title{Fuse learner with the bagging technique and oversampling for imbalancy correction.

Fuses a learner with the bagging method
(i.e., similar to what a \code{randomForest} does).
Creates a learner object, which can be
used like any other learner object.
Models can easily be accessed via \code{\link{getBaggingModels}}.

OverBagging is implemented as follows:
For each iteration a random data subset is sampled. Minority class examples
are oversampled and majority class examples are sampled with replacement.
Note that this is usually handled in a slightly different way
in the random forest where features are sampled at each tree split).

Prediction works as follows:
For classification we do majority voting to create a discrete label and
probabilities are predicted by considering the proportions of all predicted labels.}
\usage{
makeOverBaggingWrapper(learner, obw.iters = 10L, obw.rate = 2,
  obw.maxcl = "boot", predict.type = "response")
}
\arguments{
\item{learner}{[\code{\link{Learner}}]\cr
The learner. Prediction type of the basic learner must be \dQuote{response}.}

\item{obw.iters}{[\code{integer(1)}]\cr
Iterations = number of fitted models in bagging.
Default is 10.}

\item{obw.rate}{[\code{numeric(1)}]\cr
Factor to upsample the smaller class in each bag.
Must be between 1 and \code{Inf},
where 1 means no oversampling and 2 would mean doubling the class size.}

\item{predict.type}{[\code{character(1)}]\cr
Classification: \dQuote{response} (= labels) or \dQuote{prob}
(= probabilities and labels by selecting the ones with maximal probability).
Regression: \dQuote{response} (= mean response) or \dQuote{se} (= standard errors
and mean response).
Default is \dQuote{response}.}
}
\value{
[\code{\link{Learner}}].
}
\description{
Fuse learner with the bagging technique and oversampling for imbalancy correction.

Fuses a learner with the bagging method
(i.e., similar to what a \code{randomForest} does).
Creates a learner object, which can be
used like any other learner object.
Models can easily be accessed via \code{\link{getBaggingModels}}.

OverBagging is implemented as follows:
For each iteration a random data subset is sampled. Minority class examples
are oversampled and majority class examples are sampled with replacement.
Note that this is usually handled in a slightly different way
in the random forest where features are sampled at each tree split).

Prediction works as follows:
For classification we do majority voting to create a discrete label and
probabilities are predicted by considering the proportions of all predicted labels.
}

