#' @title Visualize binary classification predictions via ROC curves.
#'
#' @description
#' Plot is generated by calling \code{\link{asROCRPrediction}},
#' ROCR's \code{\link[ROCR]{performance}},
#' then plotROC's \code{ggroc} or \code{multi_ggroc} function,
#' and then either plotROC's \code{plot_journal_roc} or \code{plot_interactive_roc}.
#'
#' See these methods in ROCR and plotROC for further info.
#'
#' @template arg_plotroc_obj
#' @param meas1 [\code{character(1)}]\cr
#'   Measure on x-axis. Note that this is a measure name from *ROCR* and not from mlr!
#'   Default is \dQuote{tpr}.
#' @param meas2 [\code{character(1)}]\cr
#'   Measure on y-axis. Note that this is a measure name from *ROCR* and not from mlr!
#'   Default is \dQuote{fpr}.
#' @param perf.args [named \code{list}]\cr
#'   Further arguments passed to ROCR's \code{\link[ROCR]{performance}}.
#'   Usually not needed and \code{meas1} and \code{meas2} are set internally.
#'   Default is an empty list.
#' @param plot.args [named \code{list}]\cr
#'   Further arguments to be passed to plotROC's \code{\link[plotROC]{ggroc}} or
#'   \code{link[plotROC]{multi_ggroc}}.
#'   Default is an empty list.
#' @param print.args [named \code{list}]\cr
#'   Further arguments to be passed to plotROC's \code{\link[plotROC]{plot_journal_roc}} or
#'   \code{\link[plotROC]{plot_interactive_roc}}.
#'   Default is an empty list.
#' @param interactive [\code{logical(1)}]\cr
#'   Whether to print the plot using \code{\link[plotROC]{plot_journal_roc}}, which occurs when
#'   \code{interactive} is FALSE, or \code{\link[plotROC]{plot_interactive_roc}}, which occurs when
#'   \code{interactive} is TRUE.
#'   Default is FALSE.
#' @param alpha [\code{numeric(1)}]\cr
#'   False positive rate for confidence intervals computed by \code{\link[plotROC]{calculate_roc}}.
#'   Only applicable when \code{ci} is TRUE and a single Prediction or ResampleResult object is passed.
#'   Default is .05.
#' @param ci [\code{logical(1)}]\cr
#'   Whether to compute 1 - alpha confidence intervals using \code{\link[plotROC]{calculate_roc}}.
#'   Only applicable when a single Prediction or Resampling object is passed.
#'   Default is FALSE.
#' @param task.id [\code{character(1)}]\cr
#'   Selected task in \code{\link{BenchmarkResult}} to do plots for, ignored otherwise.
#'   Default is first task.
#'
#' @return if \code{interactive} TRUE, the output is a standalone HTML document with the plot embedded.
#'   By default (i.e. if the argument \code{file} is not passed to \code{\link[plotROC]{plot_interactive_roc}})
#'   then the document is put in a temporary file and opened in the default brower.
#'   If \code{interactive} FALSE then a \code{ggplot2} object is returned.
#' 
#' @template ret_inv_null
#' @family roc
#' @family predict
#' @export
#' @examples
#' \dontrun{
#' lrn1 = makeLearner("classif.logreg", predict.type = "prob")
#' lrn2 = makeLearner("classif.rpart", predict.type = "prob")
#' b = benchmark(list(lrn1, lrn2), pid.task)
#' z = plotROCRCurves(b)
#' }
plotROCRCurves = function(obj, meas1 = "tpr", meas2 = "fpr",
    perf.args = list(), plot.args = list(), print.args = list(),
    interactive = FALSE, alpha = .05, ci = FALSE, task.id = NULL) {

    # lets not check the value-names from ROCR here. they might be changed behind our back later...
    assertString(meas1)
    assertString(meas2)
    assertLogical(interactive, FALSE)
    assertNumeric(alpha, 0, 1)
    assertLogical(ci, FALSE)
    assertList(perf.args, names = "unique")
    assertList(plot.args, names = "unique")
    assertList(print.args, names = "unique")
    UseMethod("plotROCRCurves")
}

#' @export
plotROCRCurves.Prediction = function(obj, meas1 = "tpr", meas2 = "fpr",
    perf.args = list(), plot.args = list(), print.args = list(),
    interactive = FALSE, alpha = .05, ci = FALSE, task.id = NULL) {

    l = namedList(names = "prediction", init = obj)
    plotROCRCurves.list(l, meas1, meas2, perf.args, plot.args, print.args,
                        interactive, alpha, ci, task.id)
}

#' @export
plotROCRCurves.ResampleResult = function(obj, meas1 = "tpr", meas2 = "fpr",
    perf.args = list(), plot.args = list(), print.args = list(),
    interactive = FALSE, alpha = .05, ci = FALSE, task.id = NULL) {

    l = namedList(names = obj$learner.id, init = obj)
    plotROCRCurves.list(l, meas1, meas2, perf.args, plot.args, print.args,
                        interactive, alpha, ci, task.id)
}

#' @export
plotROCRCurves.BenchmarkResult = function(obj, meas1 = "tpr", meas2 = "fpr",
    perf.args = list(), plot.args = list(), print.args = list(),
    interactive = FALSE, alpha = .05, ci = FALSE, task.id = NULL) {

    tids = getBMRTaskIds(obj)
    if (is.null(task.id))
        task.id = tids[1L]
    else
        assertChoice(task.id, tids)
    ps = getBMRPredictions(obj, task.ids = task.id, as.df = FALSE)[[1L]]
    plotROCRCurves.list(ps, meas1, meas2, perf.args, plot.args, print.args,
                        interactive, alpha, ci, task.id)
}

#' @export
plotROCRCurves.list = function(obj, meas1 = "tpr", meas2 = "fpr",
    perf.args = list(), plot.args = list(), print.args = list(),
    interactive = FALSE, alpha = .05, ci = FALSE, task.id = NULL) {

    assertList(obj, c("Prediction", "ResampleResult"), min.len = 1L)
    k = length(obj)
    # unwrap ResampleResult to Prediction and set default names
    if (inherits(obj[[1L]], "ResampleResult")) {
        if (is.null(names(obj)))
            names(obj) = extractSubList(obj, c("pred", "learner.id"))
        obj = extractSubList(obj, "pred", simplify = FALSE)
    }
    assertList(obj, names = "unique")
    
    if (length(perf.args) == 0L & meas1 == "tpr" & meas2 == "fpr") {
        prob = lapply(obj, getProbabilities)
        prob = do.call(cbind, prob)
        plt_data = as.data.frame(prob)
        plt_data$truth = obj[[1L]]$data$truth
        plt_data$truth = plyr::mapvalues(plt_data$truth, c("neg", "pos"), c("0", "1"))

        if (length(obj) > 1L)
            plt_data = plotROC::calculate_multi_roc(plt_data, names(obj), "truth")
        else
            plt_data = plotROC::calculate_roc(plt_data[[names(obj)]], plt_data[["truth"]], ci = ci, alpha = alpha)
      } else {
        cargs = list(measure = meas1, x.measure = meas2)
        cargs = insert(cargs, perf.args)
        plt_data = lapply(obj, function(x) {
                              cargs$prediction.obj = asROCRPrediction(x)
                              perf = do.call(ROCR::performance, cargs)
                              lookup = c("x.values", "y.values")
                              names(lookup) = c(perf@x.name, perf@y.name)
                              tp.fp = lookup[c("True positive rate", "False positive rate")]
                              plt_data = data.frame(TPF = slot(perf, tp.fp[1L])[[1L]],
                                  FPF = slot(perf, tp.fp[2L])[[1L]],
                                  c = perf@alpha.values[[1L]])
                              plt_data[is.finite(plt_data$c), ]
                          })
      }
    
    if (!("label" %in% plot.args) & length(obj) > 1L)
        plot.args = insert(plot.args, list(label = gsub("^classif\\.", "", names(obj))))
    if (length(obj) > 1L) {
        plot.args = insert(plot.args, list(datalist = plt_data))
        plt = do.call(plotROC::multi_ggroc, plot.args)
    }
    else {
        plot.args = insert(plot.args, list(rocdata = plt_data))
        plt = do.call(plotROC::ggroc, plot.args)
    }

    if (!("file" %in% names(print.args)) & interactive)
        print.args = insert(print.args, list(ggroc = plt, file = NULL))
    else if (interactive)
        print.args = insert(print.args, list(ggroc = plt)) ## argument names are different, probably a bug 
    else
        print.args = insert(print.args, list(ggroc_p = plt))
    
    if (interactive)
        out = do.call(plotROC::plot_interactive_roc, print.args)
    else
        out = do.call(plotROC::plot_journal_roc, print.args)
    return(out)
}
