<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">

        <title>Tuning - mlr tutorial</title>

        <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../css/font-awesome-4.0.3.css" rel="stylesheet">
        <link href="../css/prettify-1.0.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        

        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->
            <a class="navbar-brand" href="..">mlr tutorial</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Basics <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            <li >
                                <a href="../task/">Tasks</a>
                            </li>
                        
                            <li >
                                <a href="../learner/">Learner</a>
                            </li>
                        
                            <li >
                                <a href="../train/">Train</a>
                            </li>
                        
                            <li >
                                <a href="../predict/">Predict</a>
                            </li>
                        
                            <li >
                                <a href="../performance/">Performance</a>
                            </li>
                        
                            <li >
                                <a href="../resample/">Resampling</a>
                            </li>
                        
                            <li >
                                <a href="../benchmark_experiments/">Benchmark Experiments</a>
                            </li>
                        
                            <li >
                                <a href="../parallelization/">Parallelization</a>
                            </li>
                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Advanced <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            <li >
                                <a href="../configureMlr/">Configuration</a>
                            </li>
                        
                            <li >
                                <a href="../wrapper/">Wrapper</a>
                            </li>
                        
                            <li >
                                <a href="../makeBaggingWrapper/">Bagging</a>
                            </li>
                        
                            <li class="active">
                                <a href="./">Tuning</a>
                            </li>
                        
                            <li >
                                <a href="../feature_selection/">Feature Selection</a>
                            </li>
                        
                            <li >
                                <a href="../cost_sensitive_classif/">Cost-Sensitive Classification</a>
                            </li>
                        
                            <li >
                                <a href="../over_and_undersampling/">Over- and Undersampling</a>
                            </li>
                        
                            <li >
                                <a href="../roc_analysis/">ROC Analysis</a>
                            </li>
                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Extend <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            <li >
                                <a href="../create_learner/">Create Custom Learners</a>
                            </li>
                        
                            <li >
                                <a href="../create_measure/">Create Custom Measures</a>
                            </li>
                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Appendix <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            <li >
                                <a href="../integrated_learners/">Integrated Learners</a>
                            </li>
                        
                            <li >
                                <a href="../measures/">Performance Measures</a>
                            </li>
                        
                        </ul>
                    </li>
                
                
                </ul>
            

            
            <!-- Search, Navigation and Repo links -->
            <ul class="nav navbar-nav navbar-right">
                
                
                <li >
                    <a rel="next" href="../makeBaggingWrapper/">
                        <i class="fa fa-arrow-left"></i> Previous
                    </a>
                </li>
                <li >
                    <a rel="prev" href="../feature_selection/">
                        Next <i class="fa fa-arrow-right"></i>
                    </a>
                </li>
                
                
                <li>
                    <a href="https://github.com/berndbischl/mlr/">
                        
                            <i class="fa fa-github"></i>
                        
                        GitHub
                    </a>
                </li>
                
            </ul>
            
        </div>
    </div>
</div>

        <div class="container">
            <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#tuning-hyperparameters">Tuning Hyperparameters</a></li>
        
            <li><a href="#classification-example">Classification example</a></li>
        
    
    </ul>
</div></div>
            <div class="col-md-9" role="main">

<h1 id="tuning-hyperparameters">Tuning Hyperparameters</h1>
<p>Many machine learning algorithms have hyperparameters that need to be set.
They can either be selected by the user or through resampling,
e.g. cross-validation. Setting them by hand was already covered in the
section about <a href="../train/">training</a> and <a href="../resample/">resampling</a> -- simply use the
<code>par.val</code> argument in the <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">makeLearner</a> method.</p>
<p>Grid search is one of the standard -- albeit slow -- ways to choose an
appropriate set of parameters from a given range of values.</p>
<h2 id="classification-example">Classification example</h2>
<p>We again use the <code>iris</code> data set, included in R, but now we want to
set the parameters of a SVM with a polynomial kernel.</p>
<h3 id="simple-grid-search-with-cross-validation">Simple Grid Search with cross validation</h3>
<p>We start by loading the <em>mlr</em> package and creating a classification
task (see the part on <a href="../train/">training</a> for more information):</p>
<pre class="prettyprint well"><code class="r">task = makeClassifTask(data=iris, target=&quot;Species&quot;)
</code></pre>

<p>Next, we need to create a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeParamSet.html">ParamSet</a> object that describes
the parameter space we wish to search. This is done through the function
<a href="http://www.rdocumentation.org/packages/mlr/functions/makeParamSet.html">makeParamSet</a>. We add discrete parameters for the <code>C</code> and <code>sigma</code> parameter
of the SVM to the parameter set. More details concerning parameter sets are
explained in section parameters (FIXME).</p>
<pre class="prettyprint well"><code class="r">ps = makeParamSet(makeDiscreteParam(&quot;C&quot;, values=2^(-2:2)),
                   makeDiscreteParam(&quot;sigma&quot;, values=2^(-2:2)))
</code></pre>

<p>We will use cross-validation to assess the quality of a specific parameter
setting. For this we need to create a resampling description just
like in the <a href="../resample/">resampling</a> part of the tutorial:</p>
<pre class="prettyprint well"><code class="r">rdesc = makeResampleDesc(&quot;CV&quot;, iters=3)
</code></pre>

<p>Before we can actually tune our classifier and identify the best parameter
setting, we need an instance of a <a href="http://www.rdocumentation.org/packages/mlr/functions/TuneControl.html">TuneControl</a> object. These describe the
optimization strategy used. Here we use a grid search:</p>
<pre class="prettyprint well"><code class="r">ctrl = makeTuneControlGrid()
</code></pre>

<p>Finally, combining all the previous pieces, we can tune the SVM
using our <a href="http://www.rdocumentation.org/packages/mlr/functions/TuneControl.html">TuneControl</a> instance and the resampling strategy
described by the <code>rdesc</code> variable.</p>
<pre class="prettyprint well"><code class="r">r = tuneParams(makeLearner(&quot;classif.ksvm&quot;), task=task, resampling=rdesc, par.set=ps, control=ctrl, measures=list(mmce, setAggregation(mmce, test.sd)))
</code></pre>

<pre class="prettyprint well"><code>## Loading required package: kernlab
## [Tune] Started tuning learner classif.ksvm for parameter set:
##           Type len Def         Constr Req Trafo
## C     discrete   -   - 0.25,0.5,1,2,4   -     -
## sigma discrete   -   - 0.25,0.5,1,2,4   -     -
## With control class: TuneControlGrid
## Imputation value: 1Imputation value: Inf
</code></pre>

<pre class="prettyprint well"><code>## Error: konnte Funktion &quot;setValueCNames&quot; nicht finden
</code></pre>

<p>We used a trick, also described in FIXME multicriteria_evaluation.md, to
obtain the standard deviation in addition to the default by adding a second
measure. A quick visualization of the Grid Search can be achieved by accessing
the <code>opt.path</code> as follows.</p>
<pre class="prettyprint well"><code class="r">library(ggplot2)
head(opt.grid = as.data.frame(r$opt.path))
</code></pre>

<pre class="prettyprint well"><code>## Error: Objekt 'r' nicht gefunden
</code></pre>

<pre class="prettyprint well"><code class="r">g = ggplot(opt.grid, aes(x=C, y=sigma, fill=mmce.test.mean, label=round(mmce.test.sd,3)))
</code></pre>

<pre class="prettyprint well"><code>## Error: Objekt 'opt.grid' nicht gefunden
</code></pre>

<pre class="prettyprint well"><code class="r">g + geom_tile() + geom_text(color=&quot;white&quot;)
</code></pre>

<pre class="prettyprint well"><code>## Error: Objekt 'g' nicht gefunden
</code></pre>

<p>Let's take a closer look at the example above. The parameter grid has to be a
named list and every entry has to be named according to the corresponding
parameter of the underlying <strong>R</strong> function (in this case "ksvm" from the kernlab
package, see its respective help page). The value of each entry is a vector of
feasible values for this hyperparameter. The complete grid is simply the
cross-product of all feasible values.</p>
<p>Please note that whenever parameters in the underlying <strong>R</strong> functions should be
passed within a list structure, <strong>mlr</strong> tries to give you direct access to
each parameter and get rid of the list structure. This is the case for example
with <code>ksvm</code>.</p>
<p>Tune now simply performs the cross-validation for every element of the
cross-product and selects the one with the best mean performance
measure.</p>
<p>Unfortunately, it's not clear how reliable the results are. One might
want to find out if the configurations vary for slightly different data sets.
A good approach for getting a better feeling of the best parameter setting
is a nested cross-validation.</p>
<h3 id="nested-cross-validation">Nested Cross Validation</h3>
<p>Let's run a nested CV with 5 folds in the outer loop and 3 folds in the
inner loop on the above example.</p>
<pre class="prettyprint well"><code class="r">task = makeClassifTask(data=iris, target=&quot;Species&quot;)
ps = makeParamSet(makeDiscreteParam(&quot;C&quot;, values=2^(-2:2)),
                   makeDiscreteParam(&quot;sigma&quot;, values=2^(-2:2)))
ctrl = makeTuneControlGrid()

rin = makeResampleDesc(&quot;CV&quot;, iters=3)
rout = makeResampleDesc(&quot;CV&quot;, iters=5)

lrn = makeTuneWrapper(makeLearner(&quot;classif.ksvm&quot;), resampling=rin,
                       par.set=ps, control=ctrl, show.info=FALSE)
</code></pre>

<p>Now we can run our nested CV. For further evaluations, we may
want to extract the results of the tuning run as well. Please note that storing
entire models may be expensive.</p>
<pre class="prettyprint well"><code class="r">r = resample(lrn, task, resampling = rout, extract = getTuneResult, show.info = FALSE)
</code></pre>

<pre class="prettyprint well"><code>## Error: konnte Funktion &quot;setValueCNames&quot; nicht finden
</code></pre>

<pre class="prettyprint well"><code>## Timing stopped at: 0.021 0 0.024
</code></pre>

<p>Finally, we can compare the results obtained in the different iterations. We
receive one optimal setting for each of the 5 outer folds, including the
corresponding mmce on the inner cross-validations:</p>
<pre class="prettyprint well"><code class="r">r$extract
</code></pre>

<pre class="prettyprint well"><code>## Error: Objekt 'r' nicht gefunden
</code></pre>

<p>As you can see, the optimal configuration usually depends on the data. You may
be able to identify a <em>range</em> of parameter settings that achieve good
performance though, e.g. the values for C should be at least 1 and the values
for sigma should be between 0 and 1.</p>
<p>If we want to find out how good those configurations are on the entire data
set, we can still look at the measures that we already know from
<a href="../resample/">Resampling</a>.</p>
<pre class="prettyprint well"><code class="r">r$measures.test
</code></pre>

<pre class="prettyprint well"><code>## Error: Objekt 'r' nicht gefunden
</code></pre>

<pre class="prettyprint well"><code class="r">r$aggr
</code></pre>

<pre class="prettyprint well"><code>## Error: Objekt 'r' nicht gefunden
</code></pre>

<p>Thus, we receive 5 misclassification errors (one for each optimal parameter
configuration per outer fold) and one aggregated version, i.e. the mean,
of those 5 values.</p>
<h3 id="visualization">Visualization</h3>
<p>To extract the <code>opt.path</code>s we have to access the inner cross validations.</p>
<pre class="prettyprint well"><code class="r">opt.paths = lapply(r$extract, function(x) as.data.frame(x$opt.path))
</code></pre>

<pre class="prettyprint well"><code>## Error: Objekt 'r' nicht gefunden
</code></pre>

<pre class="prettyprint well"><code class="r">opt.mmce = lapply(opt.paths, function(x) x$mmce.test.mean)
</code></pre>

<pre class="prettyprint well"><code>## Error: Objekt 'opt.paths' nicht gefunden
</code></pre>

<pre class="prettyprint well"><code class="r">opt.grid = opt.paths[[1]][,1:2]
</code></pre>

<pre class="prettyprint well"><code>## Error: Objekt 'opt.paths' nicht gefunden
</code></pre>

<pre class="prettyprint well"><code class="r">opt.grid$mmce.test.mean = apply(simplify2array(opt.mmce),1, mean)
</code></pre>

<pre class="prettyprint well"><code>## Error: Objekt 'opt.mmce' nicht gefunden
</code></pre>

<pre class="prettyprint well"><code class="r">g = ggplot(opt.grid, aes(x=C, y=sigma, fill=mmce.test.mean))
</code></pre>

<pre class="prettyprint well"><code>## Error: Objekt 'opt.grid' nicht gefunden
</code></pre>

<pre class="prettyprint well"><code class="r">g + geom_tile()
</code></pre>

<pre class="prettyprint well"><code>## Error: Objekt 'g' nicht gefunden
</code></pre>

<h3 id="regression-example">Regression example</h3>
<p>Let's tune <code>k</code> of a <code>k</code>-nearest neighbour regression model (implemented
in package <code>kknn</code>) on the <code>BostonHousing</code> data set.</p>
<pre class="prettyprint well"><code class="r">data(BostonHousing, package = &quot;mlbench&quot;)

task = makeRegrTask(data = BostonHousing, target = &quot;medv&quot;)

## Range of the value k
ps = makeParamSet(makeDiscreteParam(&quot;k&quot;, 1:7))

## Evaluate with 5-fold cross-validation
rdesc = makeResampleDesc(&quot;CV&quot;, iters = 5)

## Create a grid tuner:
ctrl = makeTuneControlGrid()

## Create a learner:
lrn = makeLearner(&quot;regr.kknn&quot;)

## Tune k-nearest neighbour regression with mean squared error as default measure
tuneParams(learner=lrn, task=task, resampling=rdesc, par.set=ps, control=ctrl, measures=mse)
</code></pre>

</div>
        </div>

        <footer class="col-md-12">
            <hr>
            
            <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>

        

        <script src="https://code.jquery.com/jquery-1.10.2.min.js"></script>
        <script src="../js/bootstrap-3.0.3.min.js"></script>
        <script src="../js/prettify-1.0.min.js"></script>
        <script src="../js/base.js"></script>
        
    </body>
</html>