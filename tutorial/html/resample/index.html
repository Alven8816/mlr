<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">

        <title>Resampling - mlr tutorial</title>

        <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../css/font-awesome-4.0.3.css" rel="stylesheet">
        <link href="../css/prettify-1.0.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        

        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->
            <a class="navbar-brand" href="..">mlr tutorial</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Basics <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            <li >
                                <a href="../task/">Tasks</a>
                            </li>
                        
                            <li >
                                <a href="../learner/">Learner</a>
                            </li>
                        
                            <li >
                                <a href="../train/">Train</a>
                            </li>
                        
                            <li >
                                <a href="../predict/">Predict</a>
                            </li>
                        
                            <li >
                                <a href="../performance/">Performance</a>
                            </li>
                        
                            <li class="active">
                                <a href="./">Resampling</a>
                            </li>
                        
                            <li >
                                <a href="../benchmark_experiments/">Benchmark Experiments</a>
                            </li>
                        
                            <li >
                                <a href="../parallelization/">Parallelization</a>
                            </li>
                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Advanced <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            <li >
                                <a href="../configureMlr/">Configuration</a>
                            </li>
                        
                            <li >
                                <a href="../wrapper/">Wrapped Learners</a>
                            </li>
                        
                            <li >
                                <a href="../makeBaggingWrapper/">Bagging</a>
                            </li>
                        
                            <li >
                                <a href="../tune/">Tuning</a>
                            </li>
                        
                            <li >
                                <a href="../feature_selection/">Feature Selection</a>
                            </li>
                        
                            <li >
                                <a href="../cost_sensitive_classif/">Cost-Sensitive Classification</a>
                            </li>
                        
                            <li >
                                <a href="../over_and_undersampling/">Imbalanced Classification Problems</a>
                            </li>
                        
                            <li >
                                <a href="../roc_analysis/">ROC Analysis</a>
                            </li>
                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Extend <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            <li >
                                <a href="../create_learner/">Create Custom Learners</a>
                            </li>
                        
                            <li >
                                <a href="../create_measure/">Create Custom Measures</a>
                            </li>
                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Appendix <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            <li >
                                <a href="../integrated_learners/">Integrated Learners</a>
                            </li>
                        
                            <li >
                                <a href="../measures/">Implemented Performance Measures</a>
                            </li>
                        
                        </ul>
                    </li>
                
                
                </ul>
            

            
            <!-- Search, Navigation and Repo links -->
            <ul class="nav navbar-nav navbar-right">
                
                
                <li >
                    <a rel="next" href="../performance/">
                        <i class="fa fa-arrow-left"></i> Previous
                    </a>
                </li>
                <li >
                    <a rel="prev" href="../benchmark_experiments/">
                        Next <i class="fa fa-arrow-right"></i>
                    </a>
                </li>
                
                
                <li>
                    <a href="https://github.com/berndbischl/mlr/">
                        
                            <i class="fa fa-github"></i>
                        
                        GitHub
                    </a>
                </li>
                
            </ul>
            
        </div>
    </div>
</div>

        <div class="container">
            <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#resampling">Resampling</a></li>
        
            <li><a href="#stratified-resampling">Stratified resampling</a></li>
        
            <li><a href="#accessing-individual-learner-models">Accessing individual learner models</a></li>
        
            <li><a href="#resample-descriptions-and-resample-instances">Resample descriptions and resample instances</a></li>
        
            <li><a href="#aggregating-performance-values">Aggregating performance values</a></li>
        
            <li><a href="#convenience-functions">Convenience functions</a></li>
        
            <li><a href="#pre-defined-resample-instances">Pre-defined resample instances</a></li>
        
    
    </ul>
</div></div>
            <div class="col-md-9" role="main">

<h1 id="resampling">Resampling</h1>
<p>In order to assess the performance of a learning algorithm, resampling
strategies are usually used. 
The entire data set is split into (multiple) training and test sets.
You train a learner on each training set, predict on the corresponding test set (sometimes
on the training set as well) and calculate some performance measure.
Then the individual performance values are aggregated, typically by calculating the mean.
There exist various different resampling strategies, for example
cross-validation and bootstrap, to mention just two popular approaches.</p>
<p><img alt="Resampling Figure" src="../../../images/resampling.png" title="Resampling Figure" /></p>
<p>In <a href="http://www.rdocumentation.org/packages/mlr/">mlr</a> the resampling strategy can be chosen via the function <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">makeResampleDesc</a>.
The supported resampling strategies are:</p>
<ul>
<li>Cross-validation (<code>"CV"</code>),</li>
<li>Leave-one-out cross-validation (<code>"LOO""</code>),</li>
<li>Repeated cross-validation (<code>"RepCV"</code>),</li>
<li>Out-of-bag bootstrap (<code>"Bootstrap"</code>),</li>
<li>Subsampling (<code>"Subsample"</code>),</li>
<li>Holdout (training/test) (<code>"Holdout"</code>).</li>
</ul>
<p>The <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a> function then evaluates the performance of a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a> using
the specified resampling strategy for a given machine learning <a href="http://www.rdocumentation.org/packages/mlr/functions/Task.html">Task</a>.</p>
<p>In the following example the performance of the
<a href="http://www.rdocumentation.org/packages/survival/functions/coxph.html">Cox proportional hazards model</a> on the 
<a href="http://www.rdocumentation.org/packages/survival/functions/lung.html">lung</a> data set is calculated using <em>3-fold cross-validation</em>.
Generally, in <em>K-fold cross-validation</em> the data set <em>D</em> is partitioned into <em>K</em> subsets of
(approximately) equal size.
In the <em>i</em>-th step of the <em>K</em> iterations, the <em>i</em>-th subset is
used for testing, while the union of the remaining parts forms the training
set.
The default performance measure in survival analysis is the concordance index (<a href="http://www.rdocumentation.org/packages/mlr/functions/cindex.html">cindex</a>).</p>
<pre class="prettyprint well"><code class="r">## Specify the resampling strategy (3-fold cross-validation)
rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3)

## Calculate the performance
r = resample(&quot;surv.coxph&quot;, lung.task, rdesc)
</code></pre>

<pre class="prettyprint well"><code>## [Resample] cross-validation iter: 1
## [Resample] cross-validation iter: 2
## [Resample] cross-validation iter: 3
## [Resample] Result: cindex.test.mean=0.627
</code></pre>

<pre class="prettyprint well"><code class="r">r
</code></pre>

<pre class="prettyprint well"><code>## $measures.train
##   iter cindex
## 1    1     NA
## 2    2     NA
## 3    3     NA
## 
## $measures.test
##   iter cindex
## 1    1 0.5783
## 2    2 0.6324
## 3    3 0.6706
## 
## $aggr
## cindex.test.mean 
##           0.6271 
## 
## $pred
## Resampled Prediction for:
## Resample description: cross-validation with 3 iterations.
## Predict: test
## Stratification: FALSE
## predict.type: response
## threshold: 
## time (mean): 0.00
##    id truth.time truth.event response iter  set
## 2   1        455        TRUE  -0.4952    1 test
## 4   2        210        TRUE   0.9574    1 test
## 7   4        310        TRUE   0.8069    1 test
## 17 10        613        TRUE   0.1918    1 test
## 19 12         61        TRUE   0.6639    1 test
## 22 14         81        TRUE  -0.1874    1 test
## 
## $models
## NULL
## 
## $err.msgs
##   iter train predict
## 1    1  &lt;NA&gt;    &lt;NA&gt;
## 2    2  &lt;NA&gt;    &lt;NA&gt;
## 3    3  &lt;NA&gt;    &lt;NA&gt;
## 
## $extract
## $extract[[1]]
## NULL
## 
## $extract[[2]]
## NULL
## 
## $extract[[3]]
## NULL
</code></pre>

<p><code>r$measures.test</code> gives the value of the performance measure on the 3 individual test
data sets.
<code>r$aggr</code> shows the aggregated performance value.
Its name, <code>"cindex.test.mean"</code>, indicates the performance measure, <a href="http://www.rdocumentation.org/packages/mlr/functions/cindex.html">cindex</a>, and the method used
to aggregate the 3 individual performances.
<a href="http://www.rdocumentation.org/packages/mlr/functions/aggregations.html">test.mean</a> is the default method and, as the name implies, takes the mean over the
performances on the 3 test data sets.
No predictions on the training data sets were made and thus <code>r$measures.train</code> contains <code>NA</code>s.</p>
<p>If predictions for the training set are required, too, set <code>predict = "train"</code>or <code>predict = "both"</code>
in <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">makeResampleDesc</a>. This is necessary for some bootstrap methods (<em>b632</em> and <em>b632+</em>) and 
we will see some examples later on.</p>
<p><code>r$pred</code> is an object of class <a href="http://www.rdocumentation.org/packages/mlr/functions/ResamplePrediction.html">ResamplePrediction</a>.
Just as a <a href="http://www.rdocumentation.org/packages/mlr/functions/Prediction.html">Prediction</a> object (see the section on <a href="../predict/">making predictions</a>)
<code>r$pred</code> has an element called <code>"data"</code> which is a <code>data.frame</code> that contains the
predictions and in case of a supervised learning problem the true values of the target
variable.</p>
<pre class="prettyprint well"><code class="r">head(r$pred$data)
</code></pre>

<pre class="prettyprint well"><code>##    id truth.time truth.event response iter  set
## 2   1        455        TRUE  -0.4952    1 test
## 4   2        210        TRUE   0.9574    1 test
## 7   4        310        TRUE   0.8069    1 test
## 17 10        613        TRUE   0.1918    1 test
## 19 12         61        TRUE   0.6639    1 test
## 22 14         81        TRUE  -0.1874    1 test
</code></pre>

<p>The columns <code>iter</code> and <code>set</code>indicate the resampling iteration and
if an individual prediction was made on the test or the training data set.</p>
<p>In the above example the performance measure is the concordance index (<a href="http://www.rdocumentation.org/packages/mlr/functions/cindex.html">cindex</a>).
Of course, it is  possible to compute multiple performance measures at once by 
passing a list of measures
(see also the previous section on <a href="../performance/">evaluating learner performance</a>).</p>
<p>In the following we estimate the Dunn index (<a href="http://www.rdocumentation.org/packages/mlr/functions/dunn.html">dunn</a>), the Davies-Bouldin cluster
separation measure (<a href="http://www.rdocumentation.org/packages/mlr/functions/db.html">db</a>), and the time for training the learner (<a href="http://www.rdocumentation.org/packages/mlr/functions/timetrain.html">timetrain</a>)
by <em>subsampling</em> with 5 iterations.
In each iteration the data set <em>D</em> is randomly partitioned into a
training and a test set according to a given percentage, e.g., 2/3
training and 1/3 test set. If there is just one iteration, the strategy
is commonly called <em>holdout</em> or <em>test sample estimation</em>.</p>
<pre class="prettyprint well"><code class="r">## Subsampling with 5 iterations and default split 2/3
rdesc = makeResampleDesc(&quot;Subsample&quot;, iters = 5)
## Subsampling with 5 iterations and 4/5 training data
rdesc = makeResampleDesc(&quot;Subsample&quot;, iters = 5, split = 4/5)

## Calculate the three performance measures
r = resample(&quot;cluster.XMeans&quot;, mtcars.task, rdesc, measures = list(dunn, db, timetrain))
</code></pre>

<pre class="prettyprint well"><code>## [Resample] subsampling iter: 1
## [Resample] subsampling iter: 2
## [Resample] subsampling iter: 3
</code></pre>

<pre class="prettyprint well"><code>## Warning: no non-missing arguments to min; returning Inf
## Warning: no non-missing arguments to max; returning -Inf
## Warning: no non-missing arguments to min; returning Inf
## Warning: no non-missing arguments to max; returning -Inf
</code></pre>

<pre class="prettyprint well"><code>## [Resample] subsampling iter: 4
</code></pre>

<pre class="prettyprint well"><code>## Warning: no non-missing arguments to max; returning -Inf
## Warning: no non-missing arguments to min; returning Inf
## Warning: no non-missing arguments to min; returning Inf
## Warning: no non-missing arguments to max; returning -Inf
</code></pre>

<pre class="prettyprint well"><code>## [Resample] subsampling iter: 5
</code></pre>

<pre class="prettyprint well"><code>## Warning: no non-missing arguments to min; returning Inf
## Warning: no non-missing arguments to max; returning -Inf
## Warning: no non-missing arguments to min; returning Inf
## Warning: no non-missing arguments to max; returning -Inf
</code></pre>

<pre class="prettyprint well"><code>## [Resample] Result: dunn.test.mean=0.958,db.test.mean=0.425,timetrain.test.mean=0.0484
</code></pre>

<pre class="prettyprint well"><code class="r">r$aggr
</code></pre>

<pre class="prettyprint well"><code>##      dunn.test.mean        db.test.mean timetrain.test.mean 
##              0.9576              0.4254              0.0484
</code></pre>

<h2 id="stratified-resampling">Stratified resampling</h2>
<p>For classification, it is usually desirable to have the same proportion of the classes in all of the partitions of the original data set. Stratified resampling ensures this.
This is particularly useful in case of imbalanced classes. Otherwise it may happen for example 
that observations of less frequent classes are missing in some of the training sets which can
decrease the performance of the learner.
In order to conduct stratified resampling, set <code>stratify = TRUE</code> when calling <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">makeResampleDesc</a>.</p>
<pre class="prettyprint well"><code class="r">## 3-fold cross-validation
rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3, stratify = TRUE)

r = resample(&quot;classif.lda&quot;, iris.task, rdesc)
</code></pre>

<pre class="prettyprint well"><code>## [Resample] cross-validation iter: 1
## [Resample] cross-validation iter: 2
## [Resample] cross-validation iter: 3
## [Resample] Result: mmce.test.mean=0.0197
</code></pre>

<h2 id="accessing-individual-learner-models">Accessing individual learner models</h2>
<p>In each resampling iteration a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a> is fitted on the respective training set.
By default, the resulting <a href="http://www.rdocumentation.org/packages/mlr/functions/WrappedModel.html">WrappedModel</a>s are not returned by <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a>.
If you want to keep them, set <code>models = TRUE</code> when calling <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a>.</p>
<pre class="prettyprint well"><code class="r">## 3-fold cross-validation
rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3)

r = resample(&quot;classif.lda&quot;, iris.task, rdesc, models = TRUE)
</code></pre>

<pre class="prettyprint well"><code>## [Resample] cross-validation iter: 1
## [Resample] cross-validation iter: 2
## [Resample] cross-validation iter: 3
## [Resample] Result: mmce.test.mean=0.02
</code></pre>

<pre class="prettyprint well"><code class="r">r$models
</code></pre>

<pre class="prettyprint well"><code>## [[1]]
## Model for id = classif.lda class = classif.lda
## Trained on obs: 100
## Used features: 4
## Hyperparameters: 
## 
## [[2]]
## Model for id = classif.lda class = classif.lda
## Trained on obs: 100
## Used features: 4
## Hyperparameters: 
## 
## [[3]]
## Model for id = classif.lda class = classif.lda
## Trained on obs: 100
## Used features: 4
## Hyperparameters:
</code></pre>

<p>Keeping only certain information instead of entire <a href="http://www.rdocumentation.org/packages/mlr/functions/WrappedModel.html">models</a>, for example the
variable importance in a regression tree, can be achieved using the <code>extract</code> argument.
The function passed to <code>extract</code> is applied to each <a href="http://www.rdocumentation.org/packages/mlr/functions/WrappedModel.html">model</a> fitted on one of
the 3 training sets.</p>
<pre class="prettyprint well"><code class="r">## 3-fold cross-validation
rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3)

## Extract the variable importance in a regression tree
r = resample(&quot;regr.rpart&quot;, bh.task, rdesc,
    extract = function(x) x$learner.model$variable.importance)
</code></pre>

<pre class="prettyprint well"><code>## [Resample] cross-validation iter: 1
## [Resample] cross-validation iter: 2
## [Resample] cross-validation iter: 3
## [Resample] Result: mse.test.mean=21.6
</code></pre>

<pre class="prettyprint well"><code class="r">r$extract
</code></pre>

<pre class="prettyprint well"><code>## [[1]]
##   lstat      rm     nox     age    crim   indus     tax     dis     rad 
## 15632.0 11547.1  9089.6  7550.9  7354.8  7125.5  2232.5  2014.4  1283.5 
## ptratio      zn 
##  1073.1   117.3 
## 
## [[2]]
##    lstat       rm      nox    indus      dis     crim      age      tax 
## 18683.64  9153.96  3245.18  3136.51  2956.10  2879.65  2831.96  2576.20 
##  ptratio       zn      rad        b 
##  1784.05  1358.84   656.07    50.41 
## 
## [[3]]
##      rm   lstat   indus     nox     dis     age    crim ptratio     tax 
## 17652.3 12489.0  4966.9  3488.2  3441.6  3334.1  3207.1  2834.8  2612.6 
##      zn     rad       b 
##  1820.9   520.4   307.2
</code></pre>

<h2 id="resample-descriptions-and-resample-instances">Resample descriptions and resample instances</h2>
<p>As shown above, the function <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">makeResampleDesc</a> is used to specify the resampling strategy.</p>
<pre class="prettyprint well"><code class="r">rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3)
str(rdesc)
</code></pre>

<pre class="prettyprint well"><code>## List of 4
##  $ id      : chr &quot;cross-validation&quot;
##  $ iters   : int 3
##  $ predict : chr &quot;test&quot;
##  $ stratify: logi FALSE
##  - attr(*, &quot;class&quot;)= chr [1:2] &quot;CVDesc&quot; &quot;ResampleDesc&quot;
</code></pre>

<p>The result <code>rdesc</code>is an object of class <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">ResampleDesc</a> and contains,
as the name implies, a description of the resampling strategy.
In principle, this is an instruction for drawing training and test sets including
the necessary parameters like the number of iterations, the sizes of the training and test
sets etc.</p>
<p>Based on this description, the data set is randomly partitioned into multiple training and
test sets.
For each iteration, we get a set of index vectors indicating the training and test examples.
These are stored in a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleInstance.html">ResampleInstance</a>.</p>
<p>If a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">ResampleDesc</a> is passed to <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a>, it is instantiated internally.
Naturally, it is also possible to pass a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleInstance.html">ResampleInstance</a> directly.</p>
<p>A <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleInstance.html">ResampleInstance</a> can be created through the function 
<a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleInstance.html">makeResampleInstance</a> given a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">ResampleDesc</a> and either the size of 
the data set at hand or the <a href="http://www.rdocumentation.org/packages/mlr/functions/Task.html">Task</a>.
It basically performs the random drawing of indices to separate the data into training and 
test sets according to the description.</p>
<pre class="prettyprint well"><code class="r">## Create a resample instance based an a task
rin = makeResampleInstance(rdesc, task = iris.task)
rin
</code></pre>

<pre class="prettyprint well"><code>## Resample instance for 150 cases.
## Resample description: cross-validation with 3 iterations.
## Predict: test
## Stratification: FALSE
</code></pre>

<pre class="prettyprint well"><code class="r">## Create a resample instance given the size of the data set
rin = makeResampleInstance(rdesc, size = nrow(iris))
str(rin)
</code></pre>

<pre class="prettyprint well"><code>## List of 5
##  $ desc      :List of 4
##   ..$ id      : chr &quot;cross-validation&quot;
##   ..$ iters   : int 3
##   ..$ predict : chr &quot;test&quot;
##   ..$ stratify: logi FALSE
##   ..- attr(*, &quot;class&quot;)= chr [1:2] &quot;CVDesc&quot; &quot;ResampleDesc&quot;
##  $ size      : int 150
##  $ train.inds:List of 3
##   ..$ : int [1:100] 91 75 111 106 107 72 96 4 55 117 ...
##   ..$ : int [1:100] 56 111 106 107 72 96 55 33 32 78 ...
##   ..$ : int [1:100] 91 75 56 4 117 32 78 45 86 126 ...
##  $ test.inds :List of 3
##   ..$ : int [1:50] 3 5 7 11 16 21 22 24 25 29 ...
##   ..$ : int [1:50] 4 6 8 10 12 14 19 20 23 26 ...
##   ..$ : int [1:50] 1 2 9 13 15 17 18 27 28 33 ...
##  $ group     : Factor w/ 0 levels: 
##  - attr(*, &quot;class&quot;)= chr &quot;ResampleInstance&quot;
</code></pre>

<pre class="prettyprint well"><code class="r">## Access the indices of the training observations in iteration 3
rin$train.inds[[3]]
</code></pre>

<pre class="prettyprint well"><code>##   [1]  91  75  56   4 117  32  78  45  86 126 127  90 140  73  20   3 123
##  [18]  70  69   7  93  47 139  87 113  65 125 130  22  92  23 115  41 104
##  [35]  99  30 114 128  79 110  29  71 142 108  88  46 138 147 149  31  39
##  [52]  25  82  52  54  36  74  21 102  50  51  19  35 145   8  97 133 120
##  [69]  37 129 135  10  80  77  42   6  12  63  95  76  64 119  60 122 103
##  [86]  66  16  83  40  14  61 136  26  62  89 100   5 118  24  11
</code></pre>

<p>While having two separate objects, resample descriptions and instances as well as the <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a>
function seems overly complicated, it has several advantages:</p>
<ul>
<li>Resample instances allow for paired experiments, that is comparing the performance
  of several learners on exactly the same training and test sets.
  This is particularly useful if you want to add another method to a comparison experiment
  you already did.</li>
</ul>
<pre class="prettyprint well"><code class="r">rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3)
rin = makeResampleInstance(rdesc, task = iris.task)

## Calculate the performance of two learners based on the same resample instance
r.lda = resample(&quot;classif.lda&quot;, iris.task, rin, show.info = FALSE)
r.rpart = resample(&quot;classif.rpart&quot;, iris.task, rin, show.info = FALSE)
r.lda$aggr
</code></pre>

<pre class="prettyprint well"><code>## mmce.test.mean 
##           0.02
</code></pre>

<pre class="prettyprint well"><code class="r">r.rpart$aggr
</code></pre>

<pre class="prettyprint well"><code>## mmce.test.mean 
##           0.06
</code></pre>

<ul>
<li>It is easy to add other resampling methods later on. You can
  simply derive from the <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleInstance.html">ResampleInstance</a>
  class, but you do not have to touch any methods that use the
  resampling strategy.</li>
</ul>
<p>As mentioned above, when calling <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleInstance.html">makeResampleInstance</a> the index sets are drawn randomly.
Mainly for <em>holdout</em> (<em>test sample</em>) <em>estimation</em> you might want full control about the training
and tests set and specify them manually.
This can be done using the function <a href="http://www.rdocumentation.org/packages/mlr/functions/makeFixedHoldoutInstance.html">makeFixedHoldoutInstance</a>.</p>
<pre class="prettyprint well"><code class="r">rin = makeFixedHoldoutInstance(train.inds = 1:100, test.inds = 101:150, size = 150)
rin
</code></pre>

<pre class="prettyprint well"><code>## Resample instance for 150 cases.
## Resample description: holdout with 0.67 split rate.
## Predict: test
## Stratification: FALSE
</code></pre>

<h2 id="aggregating-performance-values">Aggregating performance values</h2>
<p>In resampling we get (for each measure we wish to calculate) one performance 
value (on the test set, training set, or both) for each iteration.
Subsequently, these are aggregated.
As mentioned above, mainly the mean over the performance values on the test data sets
(<a href="http://www.rdocumentation.org/packages/mlr/functions/aggregations.html">test.mean</a>) is calculated.</p>
<p>For example, a 10-fold cross validation computes 10 values for the chosen
performance measure.
The aggregated value is the mean of these 10 numbers.
<a href="http://www.rdocumentation.org/packages/mlr/">mlr</a> knows how to handle it because each <a href="http://www.rdocumentation.org/packages/mlr/functions/makeMeasure.html">Measure</a> knows how it is aggregated:</p>
<pre class="prettyprint well"><code class="r">## Mean misclassification error
mmce$aggr
</code></pre>

<pre class="prettyprint well"><code>## Aggregation function: test.mean
</code></pre>

<pre class="prettyprint well"><code class="r">## Root mean square error
rmse$aggr 
</code></pre>

<pre class="prettyprint well"><code>## Aggregation function: test.sqrt.of.mean
</code></pre>

<p>The aggregation method of a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeMeasure.html">Measure</a> can be changed via the function <a href="http://www.rdocumentation.org/packages/mlr/functions/setAggregation.html">setAggregation</a>.
See the documentation of <a href="http://www.rdocumentation.org/packages/mlr/functions/aggregations.html">aggregations</a> for available methods.</p>
<h3 id="example-calculating-mean-and-standard-deviation-of-the-error-rate">Example: Calculating mean and standard deviation of the error rate</h3>
<p><a href="http://www.rdocumentation.org/packages/mlr/functions/aggregations.html">test.sd</a> computes the standard deviation of performance values on the test sets.</p>
<pre class="prettyprint well"><code class="r">mmce.test.sd = setAggregation(mmce, test.sd)
rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3)
r = resample(&quot;classif.rpart&quot;, iris.task, rdesc, measures = list(mmce, mmce.test.sd))
</code></pre>

<pre class="prettyprint well"><code>## [Resample] cross-validation iter: 1
## [Resample] cross-validation iter: 2
## [Resample] cross-validation iter: 3
## [Resample] Result: mmce.test.mean=0.06,mmce.test.sd=0.0346
</code></pre>

<pre class="prettyprint well"><code class="r">r$aggr
</code></pre>

<pre class="prettyprint well"><code>## mmce.test.mean   mmce.test.sd 
##        0.06000        0.03464
</code></pre>

<h3 id="example-calculating-the-training-error">Example: Calculating the training error</h3>
<p>Here we calculate the mean misclassification error (<a href="http://www.rdocumentation.org/packages/mlr/functions/mmce.html">mmce</a>) on the training and the test
data sets. Note that we have to set <code>predict = "both"</code>when calling <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleDesc.html">makeResampleDesc</a>
in order to get predictions on both data sets, training and test.</p>
<pre class="prettyprint well"><code class="r">mmce.train.mean = setAggregation(mmce, train.mean)
rdesc = makeResampleDesc(&quot;CV&quot;, iters = 3, predict = &quot;both&quot;)
r = resample(&quot;classif.rpart&quot;, iris.task, rdesc, measures = list(mmce, mmce.train.mean))
</code></pre>

<pre class="prettyprint well"><code>## [Resample] cross-validation iter: 1
## [Resample] cross-validation iter: 2
## [Resample] cross-validation iter: 3
## [Resample] Result: mmce.test.mean=0.06,mmce.train.mean=0.0333
</code></pre>

<pre class="prettyprint well"><code class="r">r$measures.train
</code></pre>

<pre class="prettyprint well"><code>##   iter mmce mmce
## 1    1 0.03 0.03
## 2    2 0.03 0.03
## 3    3 0.04 0.04
</code></pre>

<pre class="prettyprint well"><code class="r">r$aggr
</code></pre>

<pre class="prettyprint well"><code>##  mmce.test.mean mmce.train.mean 
##         0.06000         0.03333
</code></pre>

<h3 id="example-bootstrap">Example: Bootstrap</h3>
<p>In <em>out-of-bag bootstrap estimation</em> <em>B</em> new data sets <em>D_1</em> to <em>D_B</em> are drawn from the 
data set <em>D</em> with replacement, each of the same size as <em>D</em>.
In the <em>i</em>-th iteration, <em>D_i</em> forms the training set, while the remaining elements from 
<em>D</em>, i.e., elements not in the training set, form the test set.</p>
<!--(
                     |resampling_desc_figure|

                     |resampling_nested_resampling_figure|
)-->

<p>The variants <em>b632</em> and <em>b632+</em> calculate a convex combination of the training performance and
the out-of-bag bootstrap performance and thus require predictions on the training sets and an
appropriate aggregation strategy.</p>
<pre class="prettyprint well"><code class="r">rdesc = makeResampleDesc(&quot;Bootstrap&quot;, predict = &quot;both&quot;, iters = 10)
b632.mmce = setAggregation(mmce, b632)
b632plus.mmce = setAggregation(mmce, b632plus)
b632.mmce
</code></pre>

<pre class="prettyprint well"><code>## Performance measure: mmce
## Properties: classif,classif.multi
## Minimize: TRUE
## Best: 0; Worst: 1
## Aggregated by: b632
</code></pre>

<pre class="prettyprint well"><code class="r">r = resample(&quot;classif.rpart&quot;, iris.task, rdesc,
    measures = list(mmce, b632.mmce, b632plus.mmce), show.info = FALSE)
head(r$measures.train)
</code></pre>

<pre class="prettyprint well"><code>##   iter    mmce    mmce    mmce
## 1    1 0.04000 0.04000 0.04000
## 2    2 0.02667 0.02667 0.02667
## 3    3 0.02667 0.02667 0.02667
## 4    4 0.04000 0.04000 0.04000
## 5    5 0.02667 0.02667 0.02667
## 6    6 0.02667 0.02667 0.02667
</code></pre>

<pre class="prettyprint well"><code class="r">r$aggr
</code></pre>

<pre class="prettyprint well"><code>## mmce.test.mean      mmce.b632  mmce.b632plus 
##        0.04857        0.04149        0.04204
</code></pre>

<h2 id="convenience-functions">Convenience functions</h2>
<p>When quickly trying out some learners, it can get tedious to write the <strong>R</strong>
code for generating a resample instance, setting the aggregation strategy and so
on. For this reason <a href="http://www.rdocumentation.org/packages/mlr/">mlr</a> provides some convenience functions for the
frequently used resampling strategies, for example <a href="$resample">holdout</a>,
<a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">crossval</a> or <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">bootstrapB632</a>. But note that you do not
have as much control and flexibility than when using <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a> with a resample
description or instance.</p>
<pre class="prettyprint well"><code class="r">holdout(&quot;regr.lm&quot;, bh.task, measures = list(mse, mae))
crossval(&quot;classif.lda&quot;, iris.task, iters = 3, measures = list(mmce, ber))
bootstrapB632(&quot;surv.coxph&quot;, lung.task, iters = 20)
</code></pre>

<h2 id="pre-defined-resample-instances">Pre-defined resample instances</h2>
<p>For each of the pre-defined <a href="http://www.rdocumentation.org/packages/mlr/functions/Task.html">Task</a>s <a href="http://www.rdocumentation.org/packages/mlr/">mlr</a> provides pre-defined 
<a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleInstance.html">ResampleInstance</a>s for 3-fold cross-validation. 
These instances are occasionally used in the remainder of this tutorial.</p>
<table>
<thead>
<tr>
<th align="left">Task</th>
<th align="left">Title</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><a href="http://www.rdocumentation.org/packages/mlr/functions/mlr.agri/">agri.rin</a></td>
<td align="left">European Union Agricultural Workforces clustering task</td>
</tr>
<tr>
<td align="left"><a href="http://www.rdocumentation.org/packages/mlr/functions/mlr.bc/">bc.rin</a></td>
<td align="left">Wisconsin Breast Cancer classification task</td>
</tr>
<tr>
<td align="left"><a href="http://www.rdocumentation.org/packages/mlr/functions/mlr.bh/">bh.rin</a></td>
<td align="left">Boston Housing regression task</td>
</tr>
<tr>
<td align="left"><a href="http://www.rdocumentation.org/packages/mlr/functions/mlr.costIris/">costIris.rin</a></td>
<td align="left">Iris cost-sensitive classification task</td>
</tr>
<tr>
<td align="left"><a href="http://www.rdocumentation.org/packages/mlr/functions/mlr.iris/">iris.rin</a></td>
<td align="left">Iris classification task</td>
</tr>
<tr>
<td align="left"><a href="http://www.rdocumentation.org/packages/mlr/functions/mlr.lung/">lung.rin</a></td>
<td align="left">NCCTG Lung Cancer survival task</td>
</tr>
<tr>
<td align="left"><a href="http://www.rdocumentation.org/packages/mlr/functions/mlr.mtcars/">mtcars.rin</a></td>
<td align="left">Motor Trend Car Road Tests clustering task</td>
</tr>
<tr>
<td align="left"><a href="http://www.rdocumentation.org/packages/mlr/functions/mlr.sonar/">sonar.rin</a></td>
<td align="left">Sonar classification task</td>
</tr>
<tr>
<td align="left"><a href="http://www.rdocumentation.org/packages/mlr/functions/mlr.wpbc/">wpbc.rin</a></td>
<td align="left">Wisonsin Prognostic Breast Cancer (WPBC) survival task</td>
</tr>
</tbody>
</table>
</div>
        </div>

        <footer class="col-md-12">
            <hr>
            
            <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>

        

        <script src="https://code.jquery.com/jquery-1.10.2.min.js"></script>
        <script src="../js/bootstrap-3.0.3.min.js"></script>
        <script src="../js/prettify-1.0.min.js"></script>
        <script src="../js/base.js"></script>
        
    </body>
</html>