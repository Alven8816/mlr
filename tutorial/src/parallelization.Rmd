# Parallelization

**R** by default doesn't make use of multiple cores.
With the integration of [parallelMap](https://github.com/berndbischl/parallelMap) into
[%mlr], it becomes easy to activate the parallel computing capabilities already
supported by [%mlr].

All you have to do is select an interface by calling one of the
[parallelStart*](&parallelMap::parallelStart) functions.
The first annotated loop [%mlr] encounters will then be automatically parallelized.
Afterwards it is good practice to call [parallelStop](&parallelMap::parallelStop).

```{r}
library("parallelMap")
parallelStartSocket(2)
r = resample("classif.lda", iris.task, iris.rin)
parallelStop()
```

On Linux or Mac OS X, you may want to use
[parallelStartMulticore](&parallelMap::parallelStartMulticore) instead.
We offer different parallelization levels for fine grained control over the parallelization.
E.g., if you do not want to parallelize the [&benchmark] function because it has only very
few iterations but want to parallelize the [resampling](&resample) of each learner instead,
you can specifically pass the ``level`` `"resample"` to the
[parallelStart*](&parallelMap::parallelStart) function.
Currently the following levels are supported:
```{r}
parallelShowRegisteredLevels()
```

For further ways of parallelizing your computations, consult the
[parallelMap tutorial](https://github.com/berndbischl/parallelMap#parallelmap) and help.
